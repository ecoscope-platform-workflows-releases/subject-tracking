# AUTOGENERATED BY ECOSCOPE-WORKFLOWS; see fingerprint in README.md for details


# ruff: noqa: E402

# %% [markdown]
# # Subject Tracking
# TODO: top level description

# %% [markdown]
# ## Imports

import os

from ecoscope_workflows_core.tasks.analysis import (
    dataframe_column_max as dataframe_column_max,
)
from ecoscope_workflows_core.tasks.analysis import (
    dataframe_column_mean as dataframe_column_mean,
)
from ecoscope_workflows_core.tasks.analysis import (
    dataframe_column_sum as dataframe_column_sum,
)
from ecoscope_workflows_core.tasks.analysis import dataframe_count as dataframe_count
from ecoscope_workflows_core.tasks.config import set_string_var as set_string_var
from ecoscope_workflows_core.tasks.config import (
    set_workflow_details as set_workflow_details,
)
from ecoscope_workflows_core.tasks.filter import (
    get_timezone_from_time_range as get_timezone_from_time_range,
)
from ecoscope_workflows_core.tasks.filter import set_time_range as set_time_range
from ecoscope_workflows_core.tasks.groupby import set_groupers as set_groupers
from ecoscope_workflows_core.tasks.groupby import split_groups as split_groups
from ecoscope_workflows_core.tasks.io import persist_text as persist_text
from ecoscope_workflows_core.tasks.io import set_er_connection as set_er_connection
from ecoscope_workflows_core.tasks.results import (
    create_map_widget_single_view as create_map_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import (
    create_plot_widget_single_view as create_plot_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import (
    create_single_value_widget_single_view as create_single_value_widget_single_view,
)
from ecoscope_workflows_core.tasks.results import gather_dashboard as gather_dashboard
from ecoscope_workflows_core.tasks.results import (
    merge_widget_views as merge_widget_views,
)
from ecoscope_workflows_core.tasks.skip import (
    any_dependency_skipped as any_dependency_skipped,
)
from ecoscope_workflows_core.tasks.skip import any_is_empty_df as any_is_empty_df
from ecoscope_workflows_core.tasks.skip import never as never
from ecoscope_workflows_core.tasks.transformation import (
    add_temporal_index as add_temporal_index,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_column_values_to_string as convert_column_values_to_string,
)
from ecoscope_workflows_core.tasks.transformation import (
    convert_values_to_timezone as convert_values_to_timezone,
)
from ecoscope_workflows_core.tasks.transformation import map_columns as map_columns
from ecoscope_workflows_core.tasks.transformation import map_values as map_values
from ecoscope_workflows_core.tasks.transformation import sort_values as sort_values
from ecoscope_workflows_core.tasks.transformation import with_unit as with_unit
from ecoscope_workflows_ext_ecoscope.tasks.analysis import (
    get_night_day_ratio as get_night_day_ratio,
)
from ecoscope_workflows_ext_ecoscope.tasks.config import (
    call_etd_from_combined_params as call_etd_from_combined_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.config import (
    get_opacity_from_combined_params as get_opacity_from_combined_params,
)
from ecoscope_workflows_ext_ecoscope.tasks.config import (
    set_etd_args_with_opacity as set_etd_args_with_opacity,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_spatial_features_group as get_spatial_features_group,
)
from ecoscope_workflows_ext_ecoscope.tasks.io import (
    get_subjectgroup_observations as get_subjectgroup_observations,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    process_relocations as process_relocations,
)
from ecoscope_workflows_ext_ecoscope.tasks.preprocessing import (
    relocations_to_trajectory as relocations_to_trajectory,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polygon_layer as create_polygon_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import (
    create_polyline_layer as create_polyline_layer,
)
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecomap as draw_ecomap
from ecoscope_workflows_ext_ecoscope.tasks.results import draw_ecoplot as draw_ecoplot
from ecoscope_workflows_ext_ecoscope.tasks.results import set_base_maps as set_base_maps
from ecoscope_workflows_ext_ecoscope.tasks.skip import (
    all_geometry_are_none as all_geometry_are_none,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    add_spatial_index as add_spatial_index,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_classification as apply_classification,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    apply_color_map as apply_color_map,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    classify_is_night as classify_is_night,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    extract_spatial_grouper_feature_group_names as extract_spatial_grouper_feature_group_names,
)
from ecoscope_workflows_ext_ecoscope.tasks.transformation import (
    resolve_spatial_feature_groups_for_spatial_groupers as resolve_spatial_feature_groups_for_spatial_groupers,
)
from ecoscope_workflows_ext_ecoscope.tasks.warning import (
    mixed_subtype_warning as mixed_subtype_warning,
)

# %% [markdown]
# ## Workflow Details

# %%
# parameters

workflow_details_params = dict(
    name=...,
    description=...,
    image_url=...,
)

# %%
# call the task


workflow_details = (
    set_workflow_details.set_task_instance_id("workflow_details")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**workflow_details_params)
    .call()
)


# %% [markdown]
# ## Data Source

# %%
# parameters

er_client_name_params = dict(
    data_source=...,
)

# %%
# call the task


er_client_name = (
    set_er_connection.set_task_instance_id("er_client_name")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**er_client_name_params)
    .call()
)


# %% [markdown]
# ## Time Range

# %%
# parameters

time_range_params = dict(
    since=...,
    until=...,
    timezone=...,
)

# %%
# call the task


time_range = (
    set_time_range.set_task_instance_id("time_range")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_format="%d %b %Y %H:%M:%S", **time_range_params)
    .call()
)


# %% [markdown]
# ## Extract Timezone Selection

# %%
# parameters

get_timezone_params = dict()

# %%
# call the task


get_timezone = (
    get_timezone_from_time_range.set_task_instance_id("get_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(time_range=time_range, **get_timezone_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

subject_obs_params = dict(
    subject_group_name=...,
)

# %%
# call the task


subject_obs = (
    get_subjectgroup_observations.set_task_instance_id("subject_obs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        client=er_client_name,
        time_range=time_range,
        raise_on_empty=False,
        include_details=False,
        include_subjectsource_details=False,
        filter="none",
        **subject_obs_params,
    )
    .call()
)


# %% [markdown]
# ## Warn if mixed subtype

# %%
# parameters

warn_if_mixed_subtype_params = dict()

# %%
# call the task


warn_if_mixed_subtype = (
    mixed_subtype_warning.set_task_instance_id("warn_if_mixed_subtype")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(subject_obs=subject_obs, **warn_if_mixed_subtype_params)
    .call()
)


# %% [markdown]
# ## Convert to timezone

# %%
# parameters

convert_to_user_timezone_params = dict()

# %%
# call the task


convert_to_user_timezone = (
    convert_values_to_timezone.set_task_instance_id("convert_to_user_timezone")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=subject_obs,
        timezone=get_timezone,
        columns=["fixtime"],
        **convert_to_user_timezone_params,
    )
    .call()
)


# %% [markdown]
# ## Group Data

# %%
# parameters

groupers_params = dict(
    groupers=...,
)

# %%
# call the task


groupers = (
    set_groupers.set_task_instance_id("groupers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**groupers_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

spatial_group_ids_params = dict()

# %%
# call the task


spatial_group_ids = (
    extract_spatial_grouper_feature_group_names.set_task_instance_id(
        "spatial_group_ids"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(groupers=groupers, **spatial_group_ids_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

fetch_all_spatial_feature_groups_params = dict()

# %%
# call the task


fetch_all_spatial_feature_groups = (
    get_spatial_features_group.set_task_instance_id("fetch_all_spatial_feature_groups")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(client=er_client_name, **fetch_all_spatial_feature_groups_params)
    .map(argnames=["spatial_features_group_name"], argvalues=spatial_group_ids)
)


# %% [markdown]
# ##

# %%
# parameters

resolved_groupers_params = dict()

# %%
# call the task


resolved_groupers = (
    resolve_spatial_feature_groups_for_spatial_groupers.set_task_instance_id(
        "resolved_groupers"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        groupers=groupers,
        spatial_feature_groups=fetch_all_spatial_feature_groups,
        **resolved_groupers_params,
    )
    .call()
)


# %% [markdown]
# ## Transform Observations to Relocations

# %%
# parameters

subject_reloc_params = dict()

# %%
# call the task


subject_reloc = (
    process_relocations.set_task_instance_id("subject_reloc")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        observations=convert_to_user_timezone,
        relocs_columns=[
            "groupby_col",
            "fixtime",
            "junk_status",
            "geometry",
            "extra__subject__name",
            "extra__subject__subject_subtype",
            "extra__subject__sex",
        ],
        filter_point_coords=[
            {"x": 180.0, "y": 90.0},
            {"x": 0.0, "y": 0.0},
            {"x": 1.0, "y": 1.0},
        ],
        **subject_reloc_params,
    )
    .call()
)


# %% [markdown]
# ## Apply Day/Night Labels to Relocations

# %%
# parameters

day_night_labels_params = dict()

# %%
# call the task


day_night_labels = (
    classify_is_night.set_task_instance_id("day_night_labels")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(relocations=subject_reloc, **day_night_labels_params)
    .call()
)


# %% [markdown]
# ## Trajectory Segment Filter

# %%
# parameters

subject_traj_params = dict(
    trajectory_segment_filter=...,
)

# %%
# call the task


subject_traj = (
    relocations_to_trajectory.set_task_instance_id("subject_traj")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(relocations=day_night_labels, **subject_traj_params)
    .call()
)


# %% [markdown]
# ## Add temporal index to Subject Trajectories

# %%
# parameters

traj_add_temporal_index_params = dict()

# %%
# call the task


traj_add_temporal_index = (
    add_temporal_index.set_task_instance_id("traj_add_temporal_index")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=subject_traj,
        time_col="segment_start",
        groupers=resolved_groupers,
        cast_to_datetime=True,
        format="mixed",
        **traj_add_temporal_index_params,
    )
    .call()
)


# %% [markdown]
# ## Add spatial index to Subject Trajectories

# %%
# parameters

traj_add_spatial_index_params = dict()

# %%
# call the task


traj_add_spatial_index = (
    add_spatial_index.set_task_instance_id("traj_add_spatial_index")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        gdf=traj_add_temporal_index,
        groupers=resolved_groupers,
        **traj_add_spatial_index_params,
    )
    .call()
)


# %% [markdown]
# ## Rename value grouper columns

# %%
# parameters

rename_grouper_columns_params = dict()

# %%
# call the task


rename_grouper_columns = (
    map_columns.set_task_instance_id("rename_grouper_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=traj_add_spatial_index,
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "extra__name": "subject_name",
            "extra__subject_subtype": "subject_subtype",
            "extra__sex": "subject_sex",
        },
        raise_if_not_found=True,
        **rename_grouper_columns_params,
    )
    .call()
)


# %% [markdown]
# ## Map Subject Sex Values

# %%
# parameters

map_subject_sex_params = dict()

# %%
# call the task


map_subject_sex = (
    map_values.set_task_instance_id("map_subject_sex")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=rename_grouper_columns,
        column_name="subject_sex",
        value_map={"male": "male", "female": "female"},
        missing_values="replace",
        replacement="unknown",
        **map_subject_sex_params,
    )
    .call()
)


# %% [markdown]
# ## Classify Trajectories By Speed

# %%
# parameters

classify_traj_speed_params = dict()

# %%
# call the task


classify_traj_speed = (
    apply_classification.set_task_instance_id("classify_traj_speed")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=map_subject_sex,
        input_column_name="speed_kmhr",
        output_column_name="speed_bins",
        classification_options={"scheme": "equal_interval", "k": 6},
        label_options={
            "label_ranges": True,
            "label_decimals": 1,
            "label_suffix": " km/h",
        },
        **classify_traj_speed_params,
    )
    .call()
)


# %% [markdown]
# ## Set Trajectory Map Title

# %%
# parameters

set_traj_map_title_params = dict()

# %%
# call the task


set_traj_map_title = (
    set_string_var.set_task_instance_id("set_traj_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Subject Group Trajectory Map", **set_traj_map_title_params)
    .call()
)


# %% [markdown]
# ## Set Time Density Map Title

# %%
# parameters

set_td_map_title_params = dict()

# %%
# call the task


set_td_map_title = (
    set_string_var.set_task_instance_id("set_td_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Home Range Map", **set_td_map_title_params)
    .call()
)


# %% [markdown]
# ## Set Night/Day Map Title

# %%
# parameters

set_night_day_map_title_params = dict()

# %%
# call the task


set_night_day_map_title = (
    set_string_var.set_task_instance_id("set_night_day_map_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Subject Group Night/Day Map", **set_night_day_map_title_params)
    .call()
)


# %% [markdown]
# ## Set NSD Chart Title

# %%
# parameters

set_nsd_chart_title_params = dict()

# %%
# call the task


set_nsd_chart_title = (
    set_string_var.set_task_instance_id("set_nsd_chart_title")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(var="Net Square Displacement", **set_nsd_chart_title_params)
    .call()
)


# %% [markdown]
# ## Split Subject Trajectories by Group

# %%
# parameters

split_subject_traj_groups_params = dict()

# %%
# call the task


split_subject_traj_groups = (
    split_groups.set_task_instance_id("split_subject_traj_groups")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        df=classify_traj_speed,
        groupers=resolved_groupers,
        **split_subject_traj_groups_params,
    )
    .call()
)


# %% [markdown]
# ## Map Base Layers

# %%
# parameters

base_map_defs_params = dict(
    base_maps=...,
)

# %%
# call the task


base_map_defs = (
    set_base_maps.set_task_instance_id("base_map_defs")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**base_map_defs_params)
    .call()
)


# %% [markdown]
# ## Sort Trajetories By Classification

# %%
# parameters

sort_traj_speed_params = dict()

# %%
# call the task


sort_traj_speed = (
    sort_values.set_task_instance_id("sort_traj_speed")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="speed_kmhr",
        ascending=True,
        na_position="last",
        **sort_traj_speed_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Apply Color to Trajectories By Speed

# %%
# parameters

colormap_traj_speed_params = dict()

# %%
# call the task


colormap_traj_speed = (
    apply_color_map.set_task_instance_id("colormap_traj_speed")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="speed_bins",
        output_column_name="speed_bins_colormap",
        colormap=["#1a9850", "#91cf60", "#d9ef8b", "#fee08b", "#fc8d59", "#d73027"],
        **colormap_traj_speed_params,
    )
    .mapvalues(argnames=["df"], argvalues=sort_traj_speed)
)


# %% [markdown]
# ## Rename columns for map tooltip display

# %%
# parameters

rename_speed_display_columns_params = dict()

# %%
# call the task


rename_speed_display_columns = (
    map_columns.set_task_instance_id("rename_speed_display_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "segment_start": "Start",
            "timespan_seconds": "Duration (s)",
            "speed_kmhr": "Speed (kph)",
            "extra__is_night": "Nighttime",
            "subject_name": "Subject Name",
            "subject_sex": "Subject Sex",
        },
        raise_if_not_found=True,
        **rename_speed_display_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=colormap_traj_speed)
)


# %% [markdown]
# ## Create map layer for each trajectory group

# %%
# parameters

traj_map_layers_params = dict(
    zoom=...,
)

# %%
# call the task


traj_map_layers = (
    create_polyline_layer.set_task_instance_id("traj_map_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"color_column": "speed_bins_colormap"},
        legend={"label_column": "speed_bins", "color_column": "speed_bins_colormap"},
        tooltip_columns=[
            "Start",
            "Duration (s)",
            "Speed (kph)",
            "Nighttime",
            "Subject Name",
            "Subject Sex",
        ],
        **traj_map_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=rename_speed_display_columns)
)


# %% [markdown]
# ## Draw Ecomaps for each trajectory group

# %%
# parameters

traj_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


traj_ecomap = (
    draw_ecomap.set_task_instance_id("traj_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": "Speed",
            "format_title": False,
            "placement": "bottom-right",
        },
        static=False,
        title=None,
        max_zoom=20,
        widget_id=set_traj_map_title,
        **traj_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=traj_map_layers)
)


# %% [markdown]
# ## Persist ecomap as Text

# %%
# parameters

ecomap_html_urls_params = dict(
    filename=...,
)

# %%
# call the task


ecomap_html_urls = (
    persist_text.set_task_instance_id("ecomap_html_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **ecomap_html_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=traj_ecomap)
)


# %% [markdown]
# ## Create Map Widgets for Trajectories

# %%
# parameters

traj_map_widgets_single_views_params = dict()

# %%
# call the task


traj_map_widgets_single_views = (
    create_map_widget_single_view.set_task_instance_id("traj_map_widgets_single_views")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_traj_map_title, **traj_map_widgets_single_views_params)
    .map(argnames=["view", "data"], argvalues=ecomap_html_urls)
)


# %% [markdown]
# ## Merge EcoMap Widget Views

# %%
# parameters

traj_grouped_map_widget_params = dict()

# %%
# call the task


traj_grouped_map_widget = (
    merge_widget_views.set_task_instance_id("traj_grouped_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=traj_map_widgets_single_views, **traj_grouped_map_widget_params)
    .call()
)


# %% [markdown]
# ## Sort Trajetories By Night/Day Classification

# %%
# parameters

sort_traj_night_day_params = dict()

# %%
# call the task


sort_traj_night_day = (
    sort_values.set_task_instance_id("sort_traj_night_day")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        column_name="extra__is_night",
        ascending=False,
        na_position="last",
        **sort_traj_night_day_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Apply Color to Trajectories By Day/Night

# %%
# parameters

colormap_traj_night_params = dict()

# %%
# call the task


colormap_traj_night = (
    apply_color_map.set_task_instance_id("colormap_traj_night")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        colormap=["#292965", "#e7a553"],
        input_column_name="extra__is_night",
        output_column_name="is_night_colors",
        **colormap_traj_night_params,
    )
    .mapvalues(argnames=["df"], argvalues=sort_traj_night_day)
)


# %% [markdown]
# ## Rename columns for map tooltip display

# %%
# parameters

rename_nightday_display_columns_params = dict()

# %%
# call the task


rename_nightday_display_columns = (
    map_columns.set_task_instance_id("rename_nightday_display_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={
            "subject_name": "Subject Name",
            "subject_sex": "Subject Sex",
            "extra__is_night": "Nighttime",
        },
        raise_if_not_found=True,
        **rename_nightday_display_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=colormap_traj_night)
)


# %% [markdown]
# ## Create map layer for each trajectory group

# %%
# parameters

traj_map_night_layers_params = dict(
    zoom=...,
)

# %%
# call the task


traj_map_night_layers = (
    create_polyline_layer.set_task_instance_id("traj_map_night_layers")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={"color_column": "is_night_colors"},
        legend={"labels": ["Night", "Day"], "colors": ["#292965", "#e7a553"]},
        tooltip_columns=["Subject Name", "Subject Sex", "Nighttime"],
        **traj_map_night_layers_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=rename_nightday_display_columns)
)


# %% [markdown]
# ## Draw Ecomaps for each trajectory group

# %%
# parameters

traj_nightday_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


traj_nightday_ecomap = (
    draw_ecomap.set_task_instance_id("traj_nightday_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": "Day / Night Movement",
            "format_title": False,
            "placement": "bottom-right",
        },
        static=False,
        title=None,
        max_zoom=20,
        widget_id=set_night_day_map_title,
        **traj_nightday_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=traj_map_night_layers)
)


# %% [markdown]
# ## Persist ecomap as Text

# %%
# parameters

ecomap_nightday_html_urls_params = dict(
    filename=...,
)

# %%
# call the task


ecomap_nightday_html_urls = (
    persist_text.set_task_instance_id("ecomap_nightday_html_urls")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **ecomap_nightday_html_urls_params,
    )
    .mapvalues(argnames=["text"], argvalues=traj_nightday_ecomap)
)


# %% [markdown]
# ## Create Map Widgets for Trajectories

# %%
# parameters

traj_map_nightday_widgets_sv_params = dict()

# %%
# call the task


traj_map_nightday_widgets_sv = (
    create_map_widget_single_view.set_task_instance_id("traj_map_nightday_widgets_sv")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_night_day_map_title, **traj_map_nightday_widgets_sv_params)
    .map(argnames=["view", "data"], argvalues=ecomap_nightday_html_urls)
)


# %% [markdown]
# ## Merge EcoMap Widget Views

# %%
# parameters

traj_nightday_grouped_map_widget_params = dict()

# %%
# call the task


traj_nightday_grouped_map_widget = (
    merge_widget_views.set_task_instance_id("traj_nightday_grouped_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=traj_map_nightday_widgets_sv, **traj_nightday_grouped_map_widget_params
    )
    .call()
)


# %% [markdown]
# ## Calculate Mean Speed Per Group

# %%
# parameters

mean_speed_params = dict()

# %%
# call the task


mean_speed = (
    dataframe_column_mean.set_task_instance_id("mean_speed")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="speed_kmhr", **mean_speed_params)
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Convert Average Speed units

# %%
# parameters

average_speed_converted_params = dict()

# %%
# call the task


average_speed_converted = (
    with_unit.set_task_instance_id("average_speed_converted")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(original_unit="km/h", new_unit="km/h", **average_speed_converted_params)
    .mapvalues(argnames=["value"], argvalues=mean_speed)
)


# %% [markdown]
# ## Create Single Value Widgets for Mean Speed Per Group

# %%
# parameters

mean_speed_sv_widgets_params = dict()

# %%
# call the task


mean_speed_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id("mean_speed_sv_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Mean Speed", decimal_places=1, **mean_speed_sv_widgets_params)
    .map(argnames=["view", "data"], argvalues=average_speed_converted)
)


# %% [markdown]
# ## Merge per group Mean Speed SV widgets

# %%
# parameters

mean_speed_grouped_sv_widget_params = dict()

# %%
# call the task


mean_speed_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("mean_speed_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=mean_speed_sv_widgets, **mean_speed_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Calculate Max Speed Per Group

# %%
# parameters

max_speed_params = dict()

# %%
# call the task


max_speed = (
    dataframe_column_max.set_task_instance_id("max_speed")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="speed_kmhr", **max_speed_params)
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Convert Max Speed units

# %%
# parameters

max_speed_converted_params = dict()

# %%
# call the task


max_speed_converted = (
    with_unit.set_task_instance_id("max_speed_converted")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(original_unit="km/h", new_unit="km/h", **max_speed_converted_params)
    .mapvalues(argnames=["value"], argvalues=max_speed)
)


# %% [markdown]
# ## Create Single Value Widgets for Max Speed Per Group

# %%
# parameters

max_speed_sv_widgets_params = dict()

# %%
# call the task


max_speed_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id("max_speed_sv_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Max Speed", decimal_places=1, **max_speed_sv_widgets_params)
    .map(argnames=["view", "data"], argvalues=max_speed_converted)
)


# %% [markdown]
# ## Merge per group Max Speed SV widgets

# %%
# parameters

max_speed_grouped_sv_widget_params = dict()

# %%
# call the task


max_speed_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("max_speed_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=max_speed_sv_widgets, **max_speed_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Calculate Number of Locations Per Group

# %%
# parameters

num_location_params = dict()

# %%
# call the task


num_location = (
    dataframe_count.set_task_instance_id("num_location")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**num_location_params)
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Create Single Value Widgets for Number of Location Per Group

# %%
# parameters

num_location_sv_widgets_params = dict()

# %%
# call the task


num_location_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id(
        "num_location_sv_widgets"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        title="Number of Locations", decimal_places=1, **num_location_sv_widgets_params
    )
    .map(argnames=["view", "data"], argvalues=num_location)
)


# %% [markdown]
# ## Merge per group Number of Locations SV widgets

# %%
# parameters

num_location_grouped_sv_widget_params = dict()

# %%
# call the task


num_location_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("num_location_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=num_location_sv_widgets, **num_location_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Calculate Day/Night Ratio Per Group

# %%
# parameters

nightday_ratio_params = dict()

# %%
# call the task


nightday_ratio = (
    get_night_day_ratio.set_task_instance_id("nightday_ratio")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(**nightday_ratio_params)
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Create Single Value Widgets for Day/Night Ratio Per Group

# %%
# parameters

nightday_ratio_sv_widgets_params = dict()

# %%
# call the task


nightday_ratio_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id(
        "nightday_ratio_sv_widgets"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        title="Night/Day Ratio", decimal_places=1, **nightday_ratio_sv_widgets_params
    )
    .map(argnames=["view", "data"], argvalues=nightday_ratio)
)


# %% [markdown]
# ## Merge per group Day/Night Ratio SV widgets

# %%
# parameters

nightday_ratio_grouped_sv_widget_params = dict()

# %%
# call the task


nightday_ratio_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("nightday_ratio_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        widgets=nightday_ratio_sv_widgets, **nightday_ratio_grouped_sv_widget_params
    )
    .call()
)


# %% [markdown]
# ## Calculate Total Distance Per Group

# %%
# parameters

total_distance_params = dict()

# %%
# call the task


total_distance = (
    dataframe_column_sum.set_task_instance_id("total_distance")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="dist_meters", **total_distance_params)
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Convert total distance units

# %%
# parameters

total_dist_converted_params = dict()

# %%
# call the task


total_dist_converted = (
    with_unit.set_task_instance_id("total_dist_converted")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(original_unit="m", new_unit="km", **total_dist_converted_params)
    .mapvalues(argnames=["value"], argvalues=total_distance)
)


# %% [markdown]
# ## Create Single Value Widgets for Total Distance Per Group

# %%
# parameters

total_distance_sv_widgets_params = dict()

# %%
# call the task


total_distance_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id(
        "total_distance_sv_widgets"
    )
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(
        title="Total Distance", decimal_places=1, **total_distance_sv_widgets_params
    )
    .map(argnames=["view", "data"], argvalues=total_dist_converted)
)


# %% [markdown]
# ## Merge per group Total Distance SV widgets

# %%
# parameters

total_dist_grouped_sv_widget_params = dict()

# %%
# call the task


total_dist_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("total_dist_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=total_distance_sv_widgets, **total_dist_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ## Calculate Total Time Per Group

# %%
# parameters

total_time_params = dict()

# %%
# call the task


total_time = (
    dataframe_column_sum.set_task_instance_id("total_time")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(column_name="timespan_seconds", **total_time_params)
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Convert total time units

# %%
# parameters

total_time_converted_params = dict()

# %%
# call the task


total_time_converted = (
    with_unit.set_task_instance_id("total_time_converted")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(original_unit="s", new_unit="h", **total_time_converted_params)
    .mapvalues(argnames=["value"], argvalues=total_time)
)


# %% [markdown]
# ## Create Single Value Widgets for Total Distance Per Group

# %%
# parameters

total_time_sv_widgets_params = dict()

# %%
# call the task


total_time_sv_widgets = (
    create_single_value_widget_single_view.set_task_instance_id("total_time_sv_widgets")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title="Total Time", decimal_places=1, **total_time_sv_widgets_params)
    .map(argnames=["view", "data"], argvalues=total_time_converted)
)


# %% [markdown]
# ## Merge per group Total Distance SV widgets

# %%
# parameters

total_time_grouped_sv_widget_params = dict()

# %%
# call the task


total_time_grouped_sv_widget = (
    merge_widget_views.set_task_instance_id("total_time_grouped_sv_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=total_time_sv_widgets, **total_time_grouped_sv_widget_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

set_etd_args_params = dict(
    opacity=...,
    auto_scale_or_custom_cell_size=...,
    crs=...,
    max_speed_factor=...,
    expansion_factor=...,
    percentiles=...,
)

# %%
# call the task


set_etd_args = (
    set_etd_args_with_opacity.set_task_instance_id("set_etd_args")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(nodata_value="nan", band_count=1, **set_etd_args_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

etd_opacity_params = dict()

# %%
# call the task


etd_opacity = (
    get_opacity_from_combined_params.set_task_instance_id("etd_opacity")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=set_etd_args, **etd_opacity_params)
    .call()
)


# %% [markdown]
# ##

# %%
# parameters

td_params = dict()

# %%
# call the task


td = (
    call_etd_from_combined_params.set_task_instance_id("td")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(combined_params=set_etd_args, **td_params)
    .mapvalues(argnames=["trajectory_gdf"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Cast Percentile Column

# %%
# parameters

percentile_col_to_string_params = dict()

# %%
# call the task


percentile_col_to_string = (
    convert_column_values_to_string.set_task_instance_id("percentile_col_to_string")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(columns=["percentile"], **percentile_col_to_string_params)
    .mapvalues(argnames=["df"], argvalues=td)
)


# %% [markdown]
# ## Time Density Colormap

# %%
# parameters

td_colormap_params = dict()

# %%
# call the task


td_colormap = (
    apply_color_map.set_task_instance_id("td_colormap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        input_column_name="percentile",
        colormap="RdYlGn_r",
        output_column_name="percentile_colormap",
        **td_colormap_params,
    )
    .mapvalues(argnames=["df"], argvalues=percentile_col_to_string)
)


# %% [markdown]
# ## Create map layer from Time Density

# %%
# parameters

td_map_layer_params = dict(
    zoom=...,
)

# %%
# call the task


td_map_layer = (
    create_polygon_layer.set_task_instance_id("td_map_layer")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
            all_geometry_are_none,
        ],
        unpack_depth=1,
    )
    .partial(
        layer_style={
            "fill_color_column": "percentile_colormap",
            "opacity": etd_opacity,
            "get_line_width": 0,
        },
        legend={
            "label_column": "percentile",
            "label_suffix": " %",
            "color_column": "percentile_colormap",
            "sort": "ascending",
        },
        tooltip_columns=["percentile"],
        **td_map_layer_params,
    )
    .mapvalues(argnames=["geodataframe"], argvalues=td_colormap)
)


# %% [markdown]
# ## Draw Ecomap from Time Density

# %%
# parameters

td_ecomap_params = dict(
    view_state=...,
)

# %%
# call the task


td_ecomap = (
    draw_ecomap.set_task_instance_id("td_ecomap")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        tile_layers=base_map_defs,
        north_arrow_style={"placement": "top-left"},
        legend_style={
            "title": "Time Spent",
            "format_title": False,
            "placement": "bottom-right",
        },
        static=False,
        title=None,
        max_zoom=20,
        widget_id=set_td_map_title,
        **td_ecomap_params,
    )
    .mapvalues(argnames=["geo_layers"], argvalues=td_map_layer)
)


# %% [markdown]
# ## Persist Ecomap as Text

# %%
# parameters

td_ecomap_html_url_params = dict(
    filename=...,
)

# %%
# call the task


td_ecomap_html_url = (
    persist_text.set_task_instance_id("td_ecomap_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **td_ecomap_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=td_ecomap)
)


# %% [markdown]
# ## Create Time Density Map Widget

# %%
# parameters

td_map_widget_params = dict()

# %%
# call the task


td_map_widget = (
    create_map_widget_single_view.set_task_instance_id("td_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_td_map_title, **td_map_widget_params)
    .map(argnames=["view", "data"], argvalues=td_ecomap_html_url)
)


# %% [markdown]
# ## Merge Time Density Map Widget Views

# %%
# parameters

td_grouped_map_widget_params = dict()

# %%
# call the task


td_grouped_map_widget = (
    merge_widget_views.set_task_instance_id("td_grouped_map_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=td_map_widget, **td_grouped_map_widget_params)
    .call()
)


# %% [markdown]
# ## Rename axis label for NSD plot

# %%
# parameters

nsd_rename_display_columns_params = dict()

# %%
# call the task


nsd_rename_display_columns = (
    map_columns.set_task_instance_id("nsd_rename_display_columns")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        drop_columns=[],
        retain_columns=[],
        rename_columns={"segment_start": "Time", "nsd": "NSD (m²)"},
        raise_if_not_found=True,
        **nsd_rename_display_columns_params,
    )
    .mapvalues(argnames=["df"], argvalues=split_subject_traj_groups)
)


# %% [markdown]
# ## Draw NSD Scatter Chart

# %%
# parameters

nsd_chart_params = dict()

# %%
# call the task


nsd_chart = (
    draw_ecoplot.set_task_instance_id("nsd_chart")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        group_by="subject_name",
        ecoplot_configs=[
            {
                "x_col": "Time",
                "y_col": "NSD (m²)",
                "plot_style": {"xperiodalignment": None},
                "color_column": None,
            }
        ],
        tickformat="%b-%Y",
        widget_id=set_nsd_chart_title,
        **nsd_chart_params,
    )
    .mapvalues(argnames=["dataframe"], argvalues=nsd_rename_display_columns)
)


# %% [markdown]
# ## Persist NSD Scatter Chart as Text

# %%
# parameters

nsd_chart_html_url_params = dict(
    filename=...,
)

# %%
# call the task


nsd_chart_html_url = (
    persist_text.set_task_instance_id("nsd_chart_html_url")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        root_path=os.environ["ECOSCOPE_WORKFLOWS_RESULTS"],
        filename_suffix="v2",
        **nsd_chart_html_url_params,
    )
    .mapvalues(argnames=["text"], argvalues=nsd_chart)
)


# %% [markdown]
# ## Create NSD Plot Widget

# %%
# parameters

nsd_chart_widget_params = dict()

# %%
# call the task


nsd_chart_widget = (
    create_plot_widget_single_view.set_task_instance_id("nsd_chart_widget")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            never,
        ],
        unpack_depth=1,
    )
    .partial(title=set_nsd_chart_title, **nsd_chart_widget_params)
    .map(argnames=["view", "data"], argvalues=nsd_chart_html_url)
)


# %% [markdown]
# ## Merge NSD Widget Views

# %%
# parameters

grouped_nsd_chart_widget_merge_params = dict()

# %%
# call the task


grouped_nsd_chart_widget_merge = (
    merge_widget_views.set_task_instance_id("grouped_nsd_chart_widget_merge")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(widgets=nsd_chart_widget, **grouped_nsd_chart_widget_merge_params)
    .call()
)


# %% [markdown]
# ## Create Dashboard with Subject Tracking Widgets

# %%
# parameters

subject_tracking_dashboard_params = dict()

# %%
# call the task


subject_tracking_dashboard = (
    gather_dashboard.set_task_instance_id("subject_tracking_dashboard")
    .handle_errors()
    .with_tracing()
    .skipif(
        conditions=[
            any_is_empty_df,
            any_dependency_skipped,
        ],
        unpack_depth=1,
    )
    .partial(
        details=workflow_details,
        widgets=[
            traj_grouped_map_widget,
            mean_speed_grouped_sv_widget,
            max_speed_grouped_sv_widget,
            num_location_grouped_sv_widget,
            nightday_ratio_grouped_sv_widget,
            total_dist_grouped_sv_widget,
            total_time_grouped_sv_widget,
            td_grouped_map_widget,
            traj_nightday_grouped_map_widget,
            grouped_nsd_chart_widget_merge,
        ],
        groupers=resolved_groupers,
        time_range=time_range,
        warning=warn_if_mixed_subtype,
        **subject_tracking_dashboard_params,
    )
    .call()
)
